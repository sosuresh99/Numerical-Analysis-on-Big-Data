{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Programming Assignment - 4\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required packages\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Jacobi Method**\n",
    "\n",
    ">  Initialize the iterative solution vector $x^{(0)}$ randomly, or with the zero vector,\n",
    "\n",
    ">  for k=0:maxIteration, update every element until convergece\n",
    "\n",
    ">> for i=1:n\n",
    "$$\n",
    "x^{(k+1)}_i  = \\frac{1}{a_{ii}} \\left(b_i -\\sum_{j\\ne i}a_{ij}x^{(k)}_j\\right).\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can modify this code to answer the following\n",
    "'''\n",
    "Jacobi's iteration method for solving the system of equations Ax=b.\n",
    "p0 is the initialization for the iteration.\n",
    "'''\n",
    "def jacobi(A, b, p0, tol, maxIter=100):\n",
    "    n=len(A)\n",
    "    p = p0\n",
    "\n",
    "    for k in range(maxIter):\n",
    "        p_old = p.copy() # In python assignment is not the same as copy\n",
    "        \n",
    "        # Update every component of iterant p\n",
    "        for i in range(n):\n",
    "            sumi = b[i];\n",
    "            for j in range(n):\n",
    "                if i==j: # Diagonal elements are not included in Jacobi\n",
    "                    continue;\n",
    "                sumi = sumi - A[i,j] * p_old[j]\n",
    "            p[i] = sumi/A[i,i]\n",
    "                \n",
    "        rel_error = np.linalg.norm(p-p_old)/n # Actually 'n' should be replace by norm of p\n",
    "        # print(\"Relative error in iteration\", k+1,\":\",rel_error)\n",
    "        if rel_error<tol:\n",
    "            print(\"TOLERANCE MET BEFORE MAX-ITERATION\")\n",
    "            break\n",
    "    return p;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example System\n",
    "A = np.array([[10, -1, 2, 0],\n",
    "              [-1, 11, -1, 3],\n",
    "              [2, -1, 10, -1],\n",
    "              [0, 3, -1, 8]],dtype=float)\n",
    "b = np.array([6, 25, -11, 15],dtype=float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOLERANCE MET BEFORE MAX-ITERATION\n",
      "The solution is:  [ 0.99999816  2.00000292 -1.0000023   1.00000344]\n"
     ]
    }
   ],
   "source": [
    "## What will happen if the followign code runs\n",
    "#x = jacobi(A,b, np.array([0,0,0,0]),0.00001, 100)\n",
    "\n",
    "x = jacobi(A,b, np.array([0,0,0,0],dtype=float),0.00001, 100)\n",
    "print(\"The solution is: \",x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q1**: Modify the code for Jacobi Method for the following:\n",
    ">- (A) Implement the Gauss-Siedel Iteration in Python.Â  Solve the following system by using this method. Exact answer is (1,2,-1,1). Stopping criteria could be a relative $error < 0.00001$.\n",
    "\n",
    "$$\n",
    "\\begin{pmatrix}\n",
    "10 & -1  & 2  & 0  \\\\\n",
    "-1 & 11&-1 & 3 \\\\\n",
    "2 & -1  & 10  & -1 \\\\\n",
    "0 & 3 & -1 & 8  \n",
    "\\end{pmatrix}\n",
    "\\begin{pmatrix}\n",
    "x_1\\\\x_2\\\\x_3\\\\x_4 \n",
    "\\end{pmatrix}\n",
    "=\n",
    "\\begin{pmatrix}\n",
    "6\\\\25\\\\-11\\\\15\n",
    "\\end{pmatrix}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relative error in iteration 1 : 0.6857161893071306\n",
      "Relative error in iteration 2 : 0.13257429579699553\n",
      "Relative error in iteration 3 : 0.011207702642223044\n",
      "Relative error in iteration 4 : 0.001777405173390961\n",
      "Relative error in iteration 5 : 0.00021858973782152004\n",
      "Relative error in iteration 6 : 2.2655219734251003e-05\n",
      "Relative error in iteration 7 : 2.05484804130187e-06\n",
      "The solution is:  [ 1.00000067  2.00000002 -1.00000021  0.99999996]\n"
     ]
    }
   ],
   "source": [
    "# You can modify this code to answer the following\n",
    "'''\n",
    "Jacobi's iteration method for solving the system of equations Ax=b.\n",
    "p0 is the initialization for the iteration.\n",
    "'''\n",
    "def gauss_siedel(A, b, p0, tol, maxIter=100):\n",
    "    n=len(A)\n",
    "    p = p0\n",
    "\n",
    "    for k in range(100):\n",
    "        p_old = p.copy() # In python assignment is not the same as copy\n",
    "        # Update every component of iterant p\n",
    "        for i in range(n):\n",
    "            sumi = b[i];\n",
    "            for j in range(n):\n",
    "                if i==j: # Diagonal elements are not included in Jacobi\n",
    "                    continue;\n",
    "                sumi = sumi - A[i,j] * p[j]#bring everything to right side\n",
    "            p[i] = sumi/A[i,i]#divides it by the coefficient on that x(n) value\n",
    "           \n",
    "                \n",
    "        rel_error = np.linalg.norm(p-p_old)/(np.linalg.norm(n)) # Actually 'n' should be replace by norm of p#fix error calculation\n",
    "        print(\"Relative error in iteration\", k+1,\":\",rel_error)\n",
    "        if rel_error<tol:\n",
    "            #print(\"TOLERANCE MET BEFORE MAX-ITERATION\")\n",
    "            break\n",
    "    return p;\n",
    "\n",
    "# Example System\n",
    "A = np.array([[10, -1, 2, 0],\n",
    "              [-1, 11, -1, 3],\n",
    "              [2, -1, 10, -1],\n",
    "              [0, 3, -1, 8]],dtype=float)\n",
    "b = np.array([6, 25, -11, 15],dtype=float)\n",
    "\n",
    "## What will happen if the followign code runs\n",
    "#x = jacobi(A,b, np.array([0,0,0,0]),0.00001, 100)\n",
    "\n",
    "x = gauss_siedel(A,b, np.array([0,0,0,0],dtype=float),0.00001)\n",
    "print(\"The solution is: \",x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">- (B) Implement Successive Over-relaxation in Python and solve the above problem again with $\\omega=1.5$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relative error in iteration 1 : 0.9853903172768615\n",
      "Relative error in iteration 2 : 0.6006132179609994\n",
      "Relative error in iteration 3 : 0.3060852236334564\n",
      "Relative error in iteration 4 : 0.14043673304229104\n",
      "Relative error in iteration 5 : 0.0736418114067108\n",
      "Relative error in iteration 6 : 0.04215133707229244\n",
      "Relative error in iteration 7 : 0.0222501712132396\n",
      "Relative error in iteration 8 : 0.011343881890459213\n",
      "Relative error in iteration 9 : 0.00597985140077329\n",
      "Relative error in iteration 10 : 0.002987695279733651\n",
      "Relative error in iteration 11 : 0.0013548261447714068\n",
      "Relative error in iteration 12 : 0.0006750085856974142\n",
      "Relative error in iteration 13 : 0.00039528729376906287\n",
      "Relative error in iteration 14 : 0.00021190254309402595\n",
      "Relative error in iteration 15 : 9.879024216873605e-05\n",
      "Relative error in iteration 16 : 4.892119304940151e-05\n",
      "Relative error in iteration 17 : 2.803196205294567e-05\n",
      "Relative error in iteration 18 : 1.5097145459340654e-05\n",
      "Relative error in iteration 19 : 7.435549103236816e-06\n",
      "The solution is:  [ 0.99999297  1.9999946  -0.99999445  0.99999728]\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "def sor(A, b, w,p0, tol, maxIter=100):\n",
    "    n=len(A)\n",
    "    p = p0.copy()\n",
    "\n",
    "    for k in range(maxIter):\n",
    "        p_old = p.copy() \n",
    "        for i in range(n):\n",
    "            sumi=b[i]\n",
    "            for j in range(n):\n",
    "                if i==j: # Diagonal elements are not included in Jacobi\n",
    "                    continue;\n",
    "                sumi = sumi - A[i,j] * p[j]\n",
    "            p[i] = (((w/A[i,i])*(sumi))+((1-w)*p[i]))\n",
    "                \n",
    "        rel_error = np.linalg.norm(p-p_old)/(np.linalg.norm(n)) # Actually 'n' should be replace by norm of p\n",
    "        print(\"Relative error in iteration\", k+1,\":\",rel_error)\n",
    "        if rel_error<tol:\n",
    "            #print(\"TOLERANCE MET BEFORE MAX-ITERATION\")\n",
    "            break\n",
    "    return p;\n",
    "\n",
    "A = np.array([[10, -1, 2, 0],\n",
    "              [-1, 11, -1, 3],\n",
    "              [2, -1, 10, -1],\n",
    "              [0, 3, -1, 8]],dtype=float)\n",
    "b = np.array([6, 25, -11, 15],dtype=float)\n",
    "\n",
    "x = sor(A,b, 1.5,np.array([0,0,0,0],dtype=float),0.00001)\n",
    "print(\"The solution is: \",x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q2** : Modify the code for gradient descent method to find the minimum for a function in two variables. Show the output for the following function by using your code. \n",
    "$$\n",
    "f(x_1, x_2) = x_1^2+x_2^2-2x_1+4x_2+8\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.9999976054757287, -1.9999952109514307, 3.0000000000286686)\n"
     ]
    }
   ],
   "source": [
    "def dx(f, x_value,y_value):\n",
    "    h=0.01\n",
    "    # Numerical differentialtion of f at x_value by central difference formula\n",
    "    df_central_dif1 = (f(x_value+h,y_value) - f(x_value-h,y_value)) /(2*h)\n",
    "    return df_central_dif1\n",
    "\n",
    "def dy(f, x_value,y_value):\n",
    "    h=0.01\n",
    "    # Numerical differentialtion of f at x_value by central difference formula\n",
    "    df_central_dif2 = (f(x_value,y_value+h) - f(x_value,y_value-h)) /(2*h)\n",
    "    return df_central_dif2\n",
    "\n",
    "def gradient_descent(f, x0=0.0,y0=0.0, delta=0.000001, max_iter=100, alpha=0.1):\n",
    "    x_current = x0\n",
    "    y_current=y0\n",
    "    for i in range(max_iter):\n",
    "        # Find the derivative or approximate derivative at x_current\n",
    "        df1 = dx(f, x_current,y_current)\n",
    "        df2=dy(f,x_current,y_current)\n",
    "        # The gradient descent step\n",
    "        x_next = x_current - alpha*df1\n",
    "        y_next=y_current-alpha*df2\n",
    "        # Stop iterating once desired accuracy is achieved\n",
    "        if((np.abs(x_next - x_current) and np.abs(y_next-y_current))< delta):\n",
    "            break\n",
    "        x_current  = x_next\n",
    "        y_current=y_next\n",
    "        #print(\"\\n Iteration {0:d}: {1:.8f}\".format(i+1,x_current))\n",
    "    return x_current, y_current,f(x_current,y_current)\n",
    "\n",
    "squareFunc = lambda x, y: x**2+y**2-2*x+4*y+8\n",
    "print(gradient_descent(squareFunc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
